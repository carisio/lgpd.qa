{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b063a094-3141-401f-bb6f-7f70b14f7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gzip\n",
    "import re\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "NOME_ARQUIVO_RESULTADOS_PESQUISAS_TODOS_CHUNKS = 'outputs/3 - resultados_pesquisas/resultados_pesquisas_todos_chunks.pickle.gz'\n",
    "NOME_ARQUIVO_RESULTADOS_PESQUISAS_APENAS_ART = 'outputs/3 - resultados_pesquisas/resultados_pesquisas_apenas_art.pickle.gz'\n",
    "\n",
    "# Para abrir os arquivos depois:\n",
    "def load_pickle_gzip(path):\n",
    "    import pickle\n",
    "    import gzip\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "resultados_pesquisas_todos_chunks = load_pickle_gzip(NOME_ARQUIVO_RESULTADOS_PESQUISAS_TODOS_CHUNKS)\n",
    "resultados_pesquisas_apenas_art = load_pickle_gzip(NOME_ARQUIVO_RESULTADOS_PESQUISAS_APENAS_ART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb5836e-b96e-4479-85fe-1b7ece3360f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bm25', 'text-embedding-3-large'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_pesquisas_todos_chunks['1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b2947-62be-4ae6-b597-d54768ae2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_porcentagem = len(EXPERIMENTOS)*len(questoes)\n",
    "with tqdm(total=total_porcentagem) as pbar:\n",
    "    for experimento in EXPERIMENTOS:\n",
    "        for questao in questoes:\n",
    "            id_questao = questao['ID_QUESTAO']\n",
    "            \n",
    "            # 1) SEM NENHUM CONTEXTO\n",
    "            modelo_rag = ''\n",
    "            tipo_pesquisa_chunks = ''\n",
    "            urns_chunks = []\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "    \n",
    "            # 2) COM TODO O CONTEXTO DO DATASET CONSIDERANDO TODOS OS CHUNKS\n",
    "            modelo_rag = 'Gold'\n",
    "            tipo_pesquisa_chunks = 'todos_chunks'\n",
    "            urns_chunks = questao['URN_FUNDAMENTACAO']\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "    \n",
    "            # 3) COM TODO O CONTEXTO DO DATASET CONSIDERANDO TODOS OS CHUNKS APENAS DE ARTIGOS COMPLETOS OU JURISPRUDENCIA\n",
    "            modelo_rag = 'Gold'\n",
    "            tipo_pesquisa_chunks = 'apenas_art'\n",
    "            urns_chunks = questao['URN_FUNDAMENTACAO_APENAS_ART']\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "\n",
    "            # 4) CONSIDERANDO DE 1 A 3 CHUNKS PARA CADA MODELO DE RAG E CONSIDERANDO TODOS OS CHUNKS\n",
    "            tipo_pesquisa_chunks = 'todos_chunks'\n",
    "            modelos_rag_disponiveis_para_questao = resultados_pesquisas_todos_chunks[id_questao].keys()\n",
    "            for modelo_rag in modelos_rag_disponiveis_para_questao:\n",
    "                for n_chunks in range(1, MAX_CHUNKS_PARA_TESTAR+1):\n",
    "                    urns_chunks = list(resultados_pesquisas_todos_chunks[id_questao][modelo_rag]['urn'][0:n_chunks]))\n",
    "                    executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "                    \n",
    "            # 5) CONSIDERANDO DE 1 A 3 CHUNKS PARA CADA MODELO DE RAG E CONSIDERANDO CHUNKS DE APENAS ARTIGOS\n",
    "            tipo_pesquisa_chunks = 'apenas_art'\n",
    "            modelos_rag_disponiveis_para_questao = resultados_pesquisas_apenas_art[id_questao].keys()\n",
    "            for modelo_rag in modelos_rag_disponiveis_para_questao:\n",
    "                for n_chunks in range(1, MAX_CHUNKS_PARA_TESTAR+1):\n",
    "                    urns_chunks = list(resultados_pesquisas_apenas_art[id_questao][modelo_rag]['urn'][0:n_chunks]))\n",
    "                    executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "            \n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09935b04-2726-4327-b8fb-e91765dae763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_QUESTAO com respostas diferentes:\n",
      "8\n",
      "28\n",
      "41\n",
      "56\n",
      "61\n",
      "67\n",
      "134\n",
      "220\n",
      "254\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "arquivo = \"temp.jsonl\"  # caminho do seu arquivo\n",
    "\n",
    "respostas_por_questao = defaultdict(set)\n",
    "\n",
    "# Ler o jsonl\n",
    "with open(arquivo, \"r\", encoding=\"utf-8\") as f:\n",
    "    for linha in f:\n",
    "        dado = json.loads(linha)\n",
    "        id_questao = dado[\"ID_QUESTAO\"]\n",
    "        resposta = dado[\"RESPOSTA_LLM\"]\n",
    "        respostas_por_questao[id_questao].add(resposta)\n",
    "\n",
    "# Verificar quais tÃªm respostas diferentes\n",
    "ids_com_respostas_diferentes = [\n",
    "    id_questao\n",
    "    for id_questao, respostas in respostas_por_questao.items()\n",
    "    if len(respostas) > 1\n",
    "]\n",
    "\n",
    "print(\"ID_QUESTAO com respostas diferentes:\")\n",
    "for id_questao in ids_com_respostas_diferentes:\n",
    "    print(id_questao)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
