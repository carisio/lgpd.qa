{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699d7711-54f2-400d-8ccb-4ddde09b0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import faiss\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from getpass import getpass\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e147c1a-82f3-4ddb-ae33-cb2340bcbd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "KEY OpenAI ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_KEY = getpass(\"KEY OpenAI\")\n",
    "NOME_MODELO_EMB_OPENAI = \"text-embedding-3-large\"\n",
    "DIM_MODELO_EMB_OPENAI = 3072\n",
    "\n",
    "# Modelos disponíveis\n",
    "MODELOS_EMB_NOME_E_DIM_EMB = [(NOME_MODELO_EMB_OPENAI, DIM_MODELO_EMB_OPENAI)]\n",
    "\n",
    "# Modelos para gerar. A ideia é que, uma vez que já foi gerado, pode tirar daqui. Daí ele não precisa carregar o arquivo e ver se está lá\n",
    "MODELOS_EMB_PARA_GERAR = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c512e2f3-2dda-4aeb-876c-908a75a0449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARQUIVO_EMBEDDINGS_CHUNKS = 'outputs/embeddings_chunks.h5'\n",
    "ARQUIVO_EMBEDDINGS_QUESTOES = 'outputs/embeddings_questoes.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6ce12-67ef-46f3-95df-3d027cdac48e",
   "metadata": {},
   "source": [
    "# 1. Carregar as bases de dados de chunks e de questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23eb6ead-8ef3-4174-934d-d728faeed2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "chunks_pesquisa = load_jsonl('inputs/chunks_pesquisa.jsonl')\n",
    "questoes = load_jsonl('inputs/questoes.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189c430-0950-4c03-9981-74a6524c2d7b",
   "metadata": {},
   "source": [
    "Separa as URN/TEXTO dos chunks e as ID/ENUNCIADO das questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd43302-a14a-4b93-895b-b7792bff8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "urn_chunks = [c['URN'] for c in chunks_pesquisa]\n",
    "texto_chunks = [c['TEXTO'] for c in chunks_pesquisa]\n",
    "\n",
    "id_questoes = [q['ID_QUESTAO'] for q in questoes]\n",
    "enunciado_questoes = [q['ENUNCIADO_COM_ALTERNATIVAS'] for q in questoes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad8263-c777-4181-95ab-c8d38fe0ed8c",
   "metadata": {},
   "source": [
    "# 2. Criar as estruturas em arquivos H5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fedf22-4d63-475e-98e4-d21a0b467246",
   "metadata": {},
   "source": [
    "Garante que o arquivo existe e que tem os datasets nele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b07a6e-25fd-421e-9022-a2ad14fc7c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_estrutura_embeddings(arquivo, nome_id, lista_id):\n",
    "    with h5py.File(arquivo, \"a\") as f:\n",
    "        chunk_size=128\n",
    "        n = len(lista_id)\n",
    "        \n",
    "        if nome_id not in f:\n",
    "            # Quando criar o dataset para as URNS/ID, já cria ele preenchido com todas elas\n",
    "            f.create_dataset(\n",
    "                nome_id,\n",
    "                data=np.array(lista_id, dtype=\"S\"),  # grava tudo de uma vez\n",
    "                maxshape=(None,),\n",
    "                dtype=h5py.string_dtype(encoding=\"utf-8\"),\n",
    "                chunks=True\n",
    "            )\n",
    "    \n",
    "        for nome_modelo, dim_modelo in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "            if nome_modelo not in f:\n",
    "                # Quando criar o dataset com os embeddings do modelo, cria preenchido com nan\n",
    "                ds = f.create_dataset(\n",
    "                    nome_modelo,\n",
    "                    shape=(n, dim_modelo),\n",
    "                    maxshape=(n, dim_modelo),\n",
    "                    dtype=np.float16,\n",
    "                    compression=\"gzip\",\n",
    "                    chunks=(chunk_size, dim_modelo)\n",
    "                )\n",
    "                ds[:] = np.nan\n",
    "\n",
    "criar_estrutura_embeddings(ARQUIVO_EMBEDDINGS_CHUNKS, 'urn', urn_chunks)\n",
    "criar_estrutura_embeddings(ARQUIVO_EMBEDDINGS_QUESTOES, 'id', id_questoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76b869-ce9b-4c3d-9293-650a72f861c1",
   "metadata": {},
   "source": [
    "Funções auxiliares para saber se já existe embedding associado e para atualizar embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3a3a5a-2967-44bb-b5de-146d0c2888ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def existe_embedding(arquivo, nome_modelo, idx):\n",
    "    with h5py.File(arquivo, \"a\") as f:\n",
    "        ds = f[nome_modelo]\n",
    "\n",
    "        return not np.isnan(ds[idx, 0])\n",
    "    \n",
    "def atualizar_embedding(arquivo, nome_modelo, idx, embedding):\n",
    "    with h5py.File(arquivo, \"a\") as f:\n",
    "        ds = f[nome_modelo]\n",
    "\n",
    "        ds[idx] = np.asarray(embedding, dtype=np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6abca-056a-4c75-93dc-aeae4abb8f93",
   "metadata": {},
   "source": [
    "# 2. Cria embeddings para o campo TEXTO (chunks) e para o campo ENUNCIADO_COM_ALTERNATIVAS (questões)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c236b9b-62e3-4ab4-86e4-b731b2574099",
   "metadata": {},
   "source": [
    "Funções auxiliares para geração de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a83e7e2-4295-4b00-a69f-a5f31e84cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_emb_com_retry(id, texto, nome_modelo, func_get_emb):\n",
    "    try:\n",
    "        return func_get_emb(nome_modelo, texto)\n",
    "    except Exception as e:\n",
    "        print(f'id: {id}. Chunk muito grande. Reduzindo em 20%')\n",
    "        print(e.message)\n",
    "        # Extrai, da mensagem de erro, o total de tokens requisitados e diminui o texto proporcionalmente.\n",
    "        # No caso da openai, eles aceitam 8192 de entrada.\n",
    "        # Na hora de diminuir, garante que vai diminuir pelo menos 20% do texto de entrada\n",
    "        reduzir_para = int(len(texto)*.8)\n",
    "        if nome_modelo == EMB_MODEL_OPENAI:\n",
    "            match = re.search(r'requested\\s+(\\d+)\\s+tokens', ex.message)\n",
    "             # Se não achou a mensagem, considera 8192 para reduzir em 20%\n",
    "            total_token_requisitados = int(match.group(1)) if match else 8192\n",
    "            reduzir_para = int(min(8192/total_token_requisitados, 0.8) * len(texto))\n",
    "            \n",
    "        return extrai_emb_com_retry(id, texto[:reduzir_para], nome_modelo, func_get_emb)\n",
    "\n",
    "def extrai_emb_chunks_e_salva(nome_modelo, func_get_emb):\n",
    "    for chunk in tqdm(chunks_pesquisa):\n",
    "        urn = chunk['URN']\n",
    "        texto = chunk['TEXTO']\n",
    "    \n",
    "        if nome_modelo not in emb_chunks[urn]:\n",
    "            emb_chunks[urn][nome_modelo] = extrai_emb_com_retry(urn, texto, nome_modelo, func_get_emb)\n",
    "            #emb_chunks[urn][nome_modelo] = func_get_emb(nome_modelo, texto)\n",
    "            salvar_embeddings(NOME_ARQUIVO_EMBEDDINGS_CHUNKS, emb_chunks)\n",
    "\n",
    "def extrai_emb_questoes_e_salva(nome_modelo, func_get_emb):\n",
    "    for q in tqdm(questoes):\n",
    "        id = q['ID_QUESTAO']\n",
    "        texto = q['ENUNCIADO_COM_ALTERNATIVAS']\n",
    "    \n",
    "        if nome_modelo not in emb_questoes[id]:\n",
    "            emb_questoes[id][nome_modelo] = extrai_emb_com_retry(id, texto, nome_modelo, func_get_emb)\n",
    "            salvar_embeddings(NOME_ARQUIVO_EMBEDDINGS_QUESTOES, emb_questoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946dc23-2e2e-4af9-8456-bb10aa6c56d7",
   "metadata": {},
   "source": [
    "Função para extrair embeddings usando o modelo da openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff91428-56da-4a45-bfe0-d64c60f3303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_openai = OpenAI(api_key=OPENAI_KEY, base_url=None)\n",
    "def extrair_embeddings_openai(nome_modelo, texto):\n",
    "   return client_openai.embeddings.create(input = [texto], model=nome_modelo).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4fb6c1-e035-4e48-b184-a41383d0f675",
   "metadata": {},
   "source": [
    "Agora gera os embeddings dos chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50682a2c-2da0-49c5-8769-815b62464996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 7036/7036 [00:00<00:00, 678775.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Varre todos os urns\n",
    "for idx, urn in enumerate(tqdm(urn_chunks)):\n",
    "    texto = texto_chunks[idx]\n",
    "\n",
    "    for nome_modelo, _ in MODELOS_EMB_PARA_GERAR:\n",
    "        if not existe_embedding(ARQUIVO_EMBEDDINGS_CHUNKS, nome_modelo, idx):\n",
    "            # TODO: Depois generalizar isso daqui para não ficar tendo que fazer if com o nome dos modelos\n",
    "            if nome_modelo == NOME_MODELO_EMB_OPENAI:\n",
    "                emb_gerado = extrair_embeddings_openai(nome_modelo, texto)\n",
    "                atualizar_embedding(ARQUIVO_EMBEDDINGS_CHUNKS, nome_modelo, idx, emb_gerado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aece113-b7ef-4247-9b39-e7ca32ba1ce3",
   "metadata": {},
   "source": [
    "Gera os embeddings dos enunciados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c30b27-54e4-4e83-b89b-4aee7f85ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 638124.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Varre todos os enunciado\n",
    "for idx, id in enumerate(tqdm(id_questoes)):\n",
    "    texto = enunciado_questoes[idx]\n",
    "\n",
    "    for nome_modelo, _ in MODELOS_EMB_PARA_GERAR:\n",
    "        if not existe_embedding(ARQUIVO_EMBEDDINGS_QUESTOES, nome_modelo, idx):\n",
    "            # TODO: Depois generalizar isso daqui para não ficar tendo que fazer if com o nome dos modelos\n",
    "            if nome_modelo == NOME_MODELO_EMB_OPENAI:\n",
    "                emb_gerado = extrair_embeddings_openai(nome_modelo, texto)\n",
    "                atualizar_embedding(ARQUIVO_EMBEDDINGS_QUESTOES, nome_modelo, idx, emb_gerado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fbff6-6326-4c01-8890-17f8e3568756",
   "metadata": {},
   "source": [
    "# 3. Pesquisa semântica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db987e4-5cbb-4eba-9b3f-fb113deca87f",
   "metadata": {},
   "source": [
    "## 3.1. Testes com similaridade de cosseno e pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a29c92e7-8cca-4779-9e61-a80e2ce75b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dict_embeddings(arquivo, coluna_id):\n",
    "    embeddings = {}\n",
    "\n",
    "    with h5py.File(arquivo, \"r\") as f:\n",
    "        embeddings[coluna_id] = f[coluna_id][:].astype(str)\n",
    "        for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "            embeddings[nome_modelo] = f[nome_modelo][:]\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0af296de-3dc8-4185-951d-a73d4dd8618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emb_chunks = gerar_dict_embeddings(ARQUIVO_EMBEDDINGS_CHUNKS, 'urn')\n",
    "dict_emb_questoes = gerar_dict_embeddings(ARQUIVO_EMBEDDINGS_QUESTOES, 'id')\n",
    "\n",
    "df_emb_chunks = pd.DataFrame({\n",
    "    \"urn\": dict_emb_chunks[\"urn\"]\n",
    "})\n",
    "df_emb_questoes = pd.DataFrame({\n",
    "    \"id\": dict_emb_questoes[\"id\"]\n",
    "})\n",
    "\n",
    "for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "    df_emb_chunks[nome_modelo] = list(dict_emb_chunks[nome_modelo])\n",
    "    df_emb_questoes[nome_modelo] = list(dict_emb_questoes[nome_modelo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf22aad2-9484-4664-a728-03982271cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_proximos(id_questao, nome_modelo, n_chunks = 20):\n",
    "    emb_questao = df_emb_questoes[nome_modelo][df_emb_questoes.id == id_questao].values[0]\n",
    "\n",
    "    df_chunks_similares = df_emb_chunks.copy()\n",
    "    df_chunks_similares['similarity'] = df_chunks_similares[nome_modelo].apply(lambda x: cosine_similarity([x], [emb_questao])[0,0])\n",
    "    df_chunks_similares = df_chunks_similares.sort_values(\"similarity\", ascending=False)\n",
    "    \n",
    "    return df_chunks_similares.head(n_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e28174f-8e10-42c2-966d-45b35420e52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urn</th>\n",
       "      <th>text-embedding-3-large</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>urn:lex:br:federal:lei:2018-08-14;13709!art5_c...</td>\n",
       "      <td>[-0.04962, 0.02524, -0.000551, 0.002176, 0.031...</td>\n",
       "      <td>0.642434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6964</th>\n",
       "      <td>urn:lex:br:autoridade.nacional.protecao.dados;...</td>\n",
       "      <td>[-0.04056, 0.02379, 0.001972, -0.01602, 0.0212...</td>\n",
       "      <td>0.637140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>urn:lex:br:federal:lei:2018-08-14;13709!art23_...</td>\n",
       "      <td>[-0.0615, 0.0192, 0.003437, 0.03986, 0.01831, ...</td>\n",
       "      <td>0.633797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    urn  \\\n",
       "4080  urn:lex:br:federal:lei:2018-08-14;13709!art5_c...   \n",
       "6964  urn:lex:br:autoridade.nacional.protecao.dados;...   \n",
       "4154  urn:lex:br:federal:lei:2018-08-14;13709!art23_...   \n",
       "\n",
       "                                 text-embedding-3-large  similarity  \n",
       "4080  [-0.04962, 0.02524, -0.000551, 0.002176, 0.031...    0.642434  \n",
       "6964  [-0.04056, 0.02379, 0.001972, -0.01602, 0.0212...    0.637140  \n",
       "4154  [-0.0615, 0.0192, 0.003437, 0.03986, 0.01831, ...    0.633797  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para testar:\n",
    "get_chunks_proximos('1',NOME_MODELO_EMB_OPENAI, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3cff97-d33d-43a9-b734-48764a151cba",
   "metadata": {},
   "source": [
    "## 3.2. Testes com FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4232d514-552d-45fd-a600-dac68b580a20",
   "metadata": {},
   "source": [
    "Carregar e normalizar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e831a3d-ca00-4cf5-946f-567b2a1388ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_embeddings_faiss(arquivo, coluna_id, nome_modelo):\n",
    "    with h5py.File(arquivo, \"r\") as f:\n",
    "        ids = f[coluna_id][:].astype(str)\n",
    "        emb = f[nome_modelo][:].astype(np.float32)\n",
    "\n",
    "    return ids, emb\n",
    "\n",
    "def normalizar_embeddings(x):\n",
    "    faiss.normalize_L2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f681138-1c84-43e8-83b4-b7f2e0336bfc",
   "metadata": {},
   "source": [
    "Criar o índice.\n",
    "\n",
    "Obs.: acho que os embeddings da OpenAI já são normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54b14efc-8630-448d-8a83-09838264771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice criado com 7036 vetores\n"
     ]
    }
   ],
   "source": [
    "mapa_indice_faiss_chunks = {}\n",
    "\n",
    "for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "    urns, emb_chunks = carregar_embeddings_faiss(ARQUIVO_EMBEDDINGS_CHUNKS, 'urn', nome_modelo)\n",
    "    emb_chunks = normalizar_embeddings(emb_chunks)\n",
    "    dim = emb_chunks.shape[1]\n",
    "    \n",
    "    index_chunks = faiss.IndexFlatL2(dim)\n",
    "    index_chunks.add(emb_chunks)\n",
    "\n",
    "    mapa_indice_faiss_chunks[nome_modelo] = index_chunks\n",
    "    print(f\"Índice criado com {index_chunks.ntotal} vetores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984032d-3c3c-4f70-8c69-93dc07147fec",
   "metadata": {},
   "source": [
    "Função de busca no índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "635ccf91-6415-422c-8259-264c7545443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa id da questão / índice\n",
    "map_emb_questao_modelo = {}\n",
    "for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "    ids_q, emb_q = carregar_embeddings_faiss(ARQUIVO_EMBEDDINGS_QUESTOES, 'id', nome_modelo)\n",
    "    emb_q = normalizar_embeddings(emb_q)\n",
    "    map_emb_questao_modelo[nome_modelo] = emb_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "311bc033-b4eb-4309-90b1-dd7703a58b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa id da questão / índice\n",
    "map_id_questao = {id_: i for i, id_ in enumerate(ids_q)}\n",
    "\n",
    "def get_chunks_proximos_faiss(id_questao, nome_modelo, n_chunks=20):\n",
    "    idx_q = map_id_questao[id_questao]\n",
    "    query =  map_emb_questao_modelo[nome_modelo][idx_q:idx_q+1]  # shape (1, dim)\n",
    "    \n",
    "    distancias, indices = mapa_indice_faiss_chunks[nome_modelo].search(query, n_chunks)\n",
    "\n",
    "    resultados = []\n",
    "    for rank, (i, d) in enumerate(zip(indices[0], distancias[0])):\n",
    "        resultados.append({\n",
    "            \"rank\": rank + 1,\n",
    "            \"urn\": urns[i],\n",
    "            \"distancia_l2\": float(d),\n",
    "            \"similaridade_cosine_aprox\": 1 - d / 2\n",
    "        })\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b46f250-4add-4421-8170-e1f4a01c73e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rank': 1,\n",
       "  'urn': 'urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc6',\n",
       "  'distancia_l2': 0.7151309251785278,\n",
       "  'similaridade_cosine_aprox': 0.6424345374107361},\n",
       " {'rank': 2,\n",
       "  'urn': 'urn:lex:br:autoridade.nacional.protecao.dados;conselho.diretor:resolucao:2024-07-16;18;anexo.1!art2_cpt_inc3',\n",
       "  'distancia_l2': 0.7257207036018372,\n",
       "  'similaridade_cosine_aprox': 0.6371396481990814},\n",
       " {'rank': 3,\n",
       "  'urn': 'urn:lex:br:federal:lei:2018-08-14;13709!art23_cpt_inc3',\n",
       "  'distancia_l2': 0.7324053645133972,\n",
       "  'similaridade_cosine_aprox': 0.6337973177433014}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chunks_proximos_faiss('1', NOME_MODELO_EMB_OPENAI, n_chunks=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
