{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e48b487-d35f-4f6b-96a4-6d5dfa13c03f",
   "metadata": {},
   "source": [
    "# Caderno 4. Testes com LLMs respondendo as questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e3cebc2-631e-4a11-8f80-21b6d9d62db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gzip\n",
    "import re\n",
    "from getpass import getpass\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcecd22-aa15-4fff-af7f-b90bce6d601a",
   "metadata": {},
   "source": [
    "Nome dos arquivos que guardam os resultados das pesquisas feitas no caderno anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f7b0d80-ee87-4a48-a101-18fa69be4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOME_ARQUIVO_RESULTADOS_PESQUISAS_TODOS_CHUNKS = 'outputs/3 - resultados_pesquisas/resultados_pesquisas_todos_chunks.pickle.gz'\n",
    "NOME_ARQUIVO_RESULTADOS_PESQUISAS_APENAS_ART = 'outputs/3 - resultados_pesquisas/resultados_pesquisas_apenas_art.pickle.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163acde3-c0ff-498c-b33f-6ed5fc18c0d0",
   "metadata": {},
   "source": [
    "Configurações para testes e nome dos arquivos de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c718b98-841e-4965-aa46-ed91c918eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOME_ARQUIVO_RESPOSTAS_LLMS = 'outputs/4 - respostas_llms/respostas_llms.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df85e4ca-9e71-4909-9d45-7177c0b88942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "KEY OpenAI ········\n",
      "KEY DeepSeek ········\n",
      "KEY Maritaca ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_KEY = getpass(\"KEY OpenAI\")\n",
    "DEEPSEEK_KEY = getpass(\"KEY DeepSeek\")\n",
    "SABIA_API = getpass(\"KEY Maritaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f2c27693-cf49-4537-b1bf-222e00a5cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_5_MINI = {\n",
    "    \"CLIENT\": OpenAI(api_key=OPENAI_KEY, base_url=None),\n",
    "    \"MODEL\": \"gpt-5-mini-2025-08-07\",\n",
    "    \"MAX_CHUNKS_PARA_TESTAR\": 3\n",
    "}\n",
    "\n",
    "GPT_4_NANO = {\n",
    "    \"CLIENT\": OpenAI(api_key=OPENAI_KEY, base_url=None),\n",
    "    \"MODEL\": \"gpt-4.1-nano-2025-04-14\",\n",
    "    \"MAX_CHUNKS_PARA_TESTAR\": 1\n",
    "}\n",
    "\n",
    "DEEPSEEK_CHAT = {\n",
    "    \"CLIENT\": OpenAI(api_key=DEEPSEEK_KEY, base_url=\"https://api.deepseek.com\"),\n",
    "    \"MODEL\": \"deepseek-chat\",\n",
    "    \"MAX_CHUNKS_PARA_TESTAR\": 3\n",
    "}\n",
    "\n",
    "SABIA_3_1 = {\n",
    "    \"CLIENT\": OpenAI(api_key=SABIA_API, base_url=\"https://chat.maritaca.ai/api\"),\n",
    "    \"MODEL\": \"sabia-3.1-2025-05-08\"\n",
    "}\n",
    "\n",
    "#EXPERIMENTS = [GPT_5_MINI, DEEPSEEK_CHAT, SABIA_3_1]\n",
    "EXPERIMENTOS = [GPT_4_NANO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f83f08-3b40-407f-a1de-25f96c433c55",
   "metadata": {},
   "source": [
    "# 1. Carregar as bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d66b4b-df35-45a5-b95a-1a6fbf31c75d",
   "metadata": {},
   "source": [
    "## 1.1. Bases de chunks e questões\n",
    "\n",
    "Além de carregar as bases de chunks e questões:\n",
    "\n",
    "1. adiciona uma segunda propriedade na lista de questões para considerar apenas o nível de artigo;\n",
    "2. cria mapas para recuperar o texto da questão por id e o texto dos chunks por urn;\n",
    "3. cria uma função auxiliar para recuperar os chunks dado uma lista de urns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f77d27ef-6674-41c0-b0c9-af6667bd69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "chunks_pesquisa = load_jsonl('inputs/chunks_pesquisa.jsonl')\n",
    "questoes = load_jsonl('inputs/questoes.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28b040-2cf5-4ea2-bdc6-7f0017f994a3",
   "metadata": {},
   "source": [
    "Adiciona uma segunda propriedade na lista de questões para considerar apenas o nível de artigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6aab06cf-bbac-4fa7-8a55-8c793228cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "padrao = re.compile(r'!art\\d{1,3}')\n",
    "for questao in questoes:\n",
    "    fundamentacao_apenas_art = []\n",
    "    for urn in questao.get(\"URN_FUNDAMENTACAO\", []):\n",
    "        match = padrao.search(urn)\n",
    "\n",
    "        if match:\n",
    "            # corta exatamente no final de !artX\n",
    "            fundamentacao_apenas_art.append(urn[:match.end()])\n",
    "        else:\n",
    "            fundamentacao_apenas_art.append(urn)\n",
    "    questao[\"URN_FUNDAMENTACAO_APENAS_ART\"] = list(set(fundamentacao_apenas_art))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f15a627e-b4c3-4040-a7f5-f9cefa83aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['informativo_jurisprudencia_stj_766:aresp 2.130.619-sp']\n",
      "['informativo_jurisprudencia_stj_766:aresp 2.130.619-sp']\n",
      "...\n",
      "['urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc5', 'urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc6', 'urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc7', 'urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc8']\n",
      "['urn:lex:br:federal:lei:2018-08-14;13709!art5']\n"
     ]
    }
   ],
   "source": [
    "# Teste\n",
    "idx=694\n",
    "print(questoes[idx]['URN_FUNDAMENTACAO'])\n",
    "print(questoes[idx]['URN_FUNDAMENTACAO_APENAS_ART'])\n",
    "print('...')\n",
    "idx=3\n",
    "print(questoes[idx]['URN_FUNDAMENTACAO'])\n",
    "print(questoes[idx]['URN_FUNDAMENTACAO_APENAS_ART'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c253007-6a5b-432c-b6d5-7fc6e05c3086",
   "metadata": {},
   "source": [
    "Mapas para facilitar o retorno das questões e chunks por ids/urns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "be4385fb-5d75-4e4b-b75e-f7ca846e6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "questao_por_id = {q['ID_QUESTAO']:q for q in questoes}\n",
    "chunk_por_urn = {c['URN']:c for c in chunks_pesquisa}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac954dc-d989-4def-8499-bf04c71ff818",
   "metadata": {},
   "source": [
    "Função para pegar chunks por urn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "15e270f5-5276-43f0-9a00-e4382ad71f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_por_urns(lista_urns):\n",
    "    return [chunk_por_urn[urn] for urn in lista_urns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b90a6041-a827-4b96-8564-8a543e6f05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc5\n",
      "urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc6\n",
      "urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc7\n",
      "urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc8\n",
      "[ Dispõe sobre a proteção de dados pessoais e altera a Lei nº 12.965, de 23 de abril de 2014 (Marco Civil da Internet). | Art. 5º Para os fins desta Lei, considera-se: ] V – titular: pessoa natural a quem se referem os dados pessoais que são objeto de tratamento;\n",
      "[ Dispõe sobre a proteção de dados pessoais e altera a Lei nº 12.965, de 23 de abril de 2014 (Marco Civil da Internet). | Art. 5º Para os fins desta Lei, considera-se: ] VI – controlador: pessoa natural ou jurídica, de direito público ou privado, a quem competem as decisões referentes ao tratamento de dados pessoais;\n",
      "[ Dispõe sobre a proteção de dados pessoais e altera a Lei nº 12.965, de 23 de abril de 2014 (Marco Civil da Internet). | Art. 5º Para os fins desta Lei, considera-se: ] VII – operador: pessoa natural ou jurídica, de direito público ou privado, que realiza o tratamento de dados pessoais em nome do controlador;\n",
      "[ Dispõe sobre a proteção de dados pessoais e altera a Lei nº 12.965, de 23 de abril de 2014 (Marco Civil da Internet). | Art. 5º Para os fins desta Lei, considera-se: ] VIII – encarregado: pessoa indicada pelo controlador e operador para atuar como canal de comunicação entre o controlador, os titulares dos dados e a Autoridade Nacional de Proteção de Dados (ANPD); (Redação dada por Medida Provisória nº 869 de 27/12/2018) (Redação dada por Lei nº 13.853 de 08/07/2019)\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(questoes[3]['URN_FUNDAMENTACAO']))\n",
    "\n",
    "print('\\n'.join([c['TEXTO'] for c in get_chunks_por_urns(questoes[3]['URN_FUNDAMENTACAO'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cbf331-a6cf-4a9c-ba50-fc43c05d1492",
   "metadata": {},
   "source": [
    "## 1.2. Carrega os resultados das pesquisas de chunks realizadas no caderno anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d808a39-1320-4610-8ed9-0cc739dbef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para abrir os arquivos depois:\n",
    "def load_pickle_gzip(path):\n",
    "    import pickle\n",
    "    import gzip\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "resultados_pesquisas_todos_chunks = load_pickle_gzip(NOME_ARQUIVO_RESULTADOS_PESQUISAS_TODOS_CHUNKS)\n",
    "resultados_pesquisas_apenas_art = load_pickle_gzip(NOME_ARQUIVO_RESULTADOS_PESQUISAS_APENAS_ART)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbe498-dce5-481d-9138-2d03e4188cc6",
   "metadata": {},
   "source": [
    "# 2. Prompts para enviar para os LLMs responderem as questões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "837ef011-3f1a-4a46-826c-79ed3b09aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você é um assistente especializado em legislação brasileira.\n",
      "\n",
      "O usuário apresentará uma questão relacionada ao direito brasileiro e poderá, opcionalmente, fornecer um ou mais contextos de apoio. Esses contextos podem ou não ser relevantes para a resolução da questão, cabendo a você avaliá-los.\n",
      "\n",
      "A questão poderá ser de múltipla escolha ou do tipo certo/errado.\n",
      "\n",
      "Seu papel é analisar a questão e fornecer a resposta correta, sem consulta à internet.\n",
      "\n",
      "A resposta DEVE ser apresentada exclusivamente no formato JSON, contendo obrigatoriamente as seguintes propriedades:\n",
      "\n",
      "- \"EXPLICACAO\": texto explicativo que justifique a resposta com base jurídica adequada.\n",
      "- \"RESPOSTA\": a resposta final da questão. Caso a questão seja de múltiplica escolha, deverá ser a alternativa (por exemplo, 'A', 'B' etc). Caso a questão seja do tipo certo/errado, deverá ser 'Certo' ou 'Errado'.\n",
      "\n",
      "Não inclua nenhum texto fora do objeto JSON e sempre apresente as propriedades nesta ordem: primeiro a propriedade EXPLICACAO e, por último, a propriedade RESPOSTA.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "Você é um assistente especializado em legislação brasileira.\n",
    "\n",
    "O usuário apresentará uma questão relacionada ao direito brasileiro e poderá, opcionalmente, fornecer um ou mais contextos de apoio. Esses contextos podem ou não ser relevantes para a resolução da questão, cabendo a você avaliá-los.\n",
    "\n",
    "A questão poderá ser de múltipla escolha ou do tipo certo/errado.\n",
    "\n",
    "Seu papel é analisar a questão e fornecer a resposta correta, sem consulta à internet.\n",
    "\n",
    "A resposta DEVE ser apresentada exclusivamente no formato JSON, contendo obrigatoriamente as seguintes propriedades:\n",
    "\n",
    "- \"EXPLICACAO\": texto explicativo que justifique a resposta com base jurídica adequada.\n",
    "- \"RESPOSTA\": a resposta final da questão. Caso a questão seja de múltiplica escolha, deverá ser a alternativa (por exemplo, 'A', 'B' etc). Caso a questão seja do tipo certo/errado, deverá ser 'Certo' ou 'Errado'.\n",
    "\n",
    "Não inclua nenhum texto fora do objeto JSON e sempre apresente as propriedades nesta ordem: primeiro a propriedade EXPLICACAO e, por último, a propriedade RESPOSTA.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6c714a8d-a399-42f5-ac3b-92d614a8dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_usuario(questao, urns_chunks_contexto = []):\n",
    "    # Monta a lista numerada de contextos\n",
    "    chunks_contexto = get_chunks_por_urns(urns_chunks_contexto)\n",
    "    contextos_numerados = \"\\n\".join(\n",
    "        f\"{i + 1}. {chunk['TEXTO']}\" for i, chunk in enumerate(chunks_contexto)\n",
    "    )\n",
    "    \n",
    "    user_prompt = \"\"\"\n",
    "{questao_com_alternativas}\n",
    "\n",
    "----- CONTEXTOS DE APOIO -----\n",
    "{contextos_numerados}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return user_prompt.format(questao_com_alternativas=questao['ENUNCIADO_COM_ALTERNATIVAS'], contextos_numerados=contextos_numerados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a276c-25c9-43e7-ab79-c370c7be8a59",
   "metadata": {},
   "source": [
    "# 3. Executa os experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f50c10-0c48-400f-b90a-80fdaf9113e5",
   "metadata": {},
   "source": [
    "## 3.1. Função para carregar e salvar os experimentos em jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c82f70-a177-458c-890d-12f3c102d706",
   "metadata": {},
   "source": [
    "Os experimentos serão salvos em um arquivo JSONL com a estrutura abaixo.\n",
    "\n",
    "Obs.: O motivo da resposta do LLM não será salvo para economizar espaço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b35ac4f8-34eb-4742-a533-cc1ba93190a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUNAS = [\n",
    "    \"MODELO_LLM\", # LLM usado para gerar a resposta\n",
    "    \"ID_QUESTAO\", # ID da questão\n",
    "    \"MODELO_RAG\", # Modelo de RAG usado no contexto (Se não tiver contexto, é vazio. Se o contexto for o do dataset, é 'Gold')\n",
    "    \"TIPO_PESQUISA_CHUNKS\", # 'todos_chunks' ou 'apenas\n",
    "    \"NUM_CHUNKS\", # Número de chunks usados para o contexto\n",
    "    \"RESPOSTA_LLM\", # Resposta do LLM\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0a1c4-557f-4614-a1e0-3874285d18aa",
   "metadata": {},
   "source": [
    "Carrega ou cria o dataframe a partir do JSONL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b594ba80-1215-44e7-9637-4accf29d6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dataframe():\n",
    "    if os.path.exists(NOME_ARQUIVO_RESPOSTAS_LLMS):\n",
    "        df = pd.read_json(NOME_ARQUIVO_RESPOSTAS_LLMS, lines=True)\n",
    "        df[\"ID_QUESTAO\"] = df[\"ID_QUESTAO\"].astype(str)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=COLUNAS)\n",
    "    return df\n",
    "\n",
    "df_resultados_experimentos = carregar_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88cfb8f-4d98-4b39-a0ea-c7dc675424de",
   "metadata": {},
   "source": [
    "Salvar resultados do experimento.\n",
    "\n",
    "Para não ter que ficar reescrevendo todo o arquivo toda hora, faz o append no dataframe de resultados e no JSONL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6448317c-fccc-4aa6-9a80-aa10af17b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adiciona_resultado_experimento(df_resultados, modelo_llm, id_questao, modelo_rag, tipo_pesquisa_chunks, num_chunks, resposta_llm):\n",
    "    experimento = {\n",
    "        \"MODELO_LLM\": modelo_llm,\n",
    "        \"ID_QUESTAO\": id_questao,\n",
    "        \"MODELO_RAG\": modelo_rag,\n",
    "        \"TIPO_PESQUISA_CHUNKS\": tipo_pesquisa_chunks,\n",
    "        \"NUM_CHUNKS\": num_chunks,\n",
    "        \"RESPOSTA_LLM\": resposta_llm\n",
    "    }\n",
    "\n",
    "    df_resultados = pd.concat(\n",
    "        [df_resultados, pd.DataFrame([experimento])],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    with open(NOME_ARQUIVO_RESPOSTAS_LLMS, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(experimento, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    return df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c7df8-32db-4739-9c68-148c848ea049",
   "metadata": {},
   "source": [
    "## 3.2 Função para verificar se o experimento já existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e20fd473-1709-4870-929d-1239536fca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimento_ja_existe(df, modelo_llm, id_questao, modelo_rag, tipo_pesquisa_chunks, num_chunks):\n",
    "    filtro = (\n",
    "        (df[\"MODELO_LLM\"] == modelo_llm) &\n",
    "        (df[\"ID_QUESTAO\"] == id_questao) &\n",
    "        (df[\"MODELO_RAG\"] == modelo_rag) &\n",
    "        (df[\"TIPO_PESQUISA_CHUNKS\"] == tipo_pesquisa_chunks) &\n",
    "        (df[\"NUM_CHUNKS\"] == num_chunks)\n",
    "    )\n",
    "    return filtro.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c68871-4b7f-4c09-acfb-19b2615c341a",
   "metadata": {},
   "source": [
    "## 3.3 Função para chamar LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "021161bd-8fe7-47c7-94f3-fe2d1a6c7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_llm(experimento, questao, urns_chunks_contexto = []):\n",
    "    modelo_llm = experimento['MODEL']\n",
    "    client = experimento['CLIENT']\n",
    "\n",
    "    prompt_usuario = get_prompt_usuario(questao, urns_chunks_contexto)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=modelo_llm,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt_usuario},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    # A resposta do deepseek inicia com ```json e finalizada com ```. Filtra apenas o conteúdo dentro das chaves\n",
    "    inicio = content.find('{')\n",
    "    fim = content.rfind('}') + 1\n",
    "    \n",
    "    content = content[inicio:fim]\n",
    "\n",
    "    try:\n",
    "        retorno_llm = json.loads(content)\n",
    "\n",
    "        # Se o json não tiver o campo RESPOSTA ou se o campo RESPOSTA não for uma string, é necessário rodar novamente\n",
    "        if \"RESPOSTA\" not in retorno_llm.keys() or not isinstance(retorno_llm['RESPOSTA'], str):\n",
    "            return {\"EXPLICACAO\": \"ERRO_RODAR_NOVAMENTE\", \"RESPOSTA\": \"ERRO_RODAR_NOVAMENTE\" }\n",
    "\n",
    "        return retorno_llm\n",
    "    except:\n",
    "        return {\"EXPLICACAO\": \"ERRO_RODAR_NOVAMENTE\", \"RESPOSTA\": \"ERRO_RODAR_NOVAMENTE\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca11a8-bd7e-43fc-9462-a16654c851c5",
   "metadata": {},
   "source": [
    "## 3.4 Primeiro, executa os experimentos sem nenhum chunk e com todos os chunks necessários para responder a questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5738be32-2dd2-415e-8db4-d7315f69eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks):\n",
    "    modelo_llm = experimento['MODEL']\n",
    "    id_questao = questao['ID_QUESTAO']\n",
    "    num_chunks = len(urns_chunks)\n",
    "    \n",
    "    if not experimento_ja_existe(df_resultados_experimentos, modelo_llm, id_questao, modelo_rag, tipo_pesquisa_chunks, num_chunks):\n",
    "        json_llm = get_answer_llm(experimento, questao, urns_chunks)\n",
    "        resposta_llm = json_llm['RESPOSTA']\n",
    "        df_resultados_experimentos = adiciona_resultado_experimento(df_resultados_experimentos, modelo_llm, id_questao, modelo_rag, tipo_pesquisa_chunks, num_chunks, resposta_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e78602e8-e334-4908-bfe7-e9e0efd737ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [01:09<00:00, 10.05it/s]\n"
     ]
    }
   ],
   "source": [
    "total_porcentagem = len(EXPERIMENTOS)*len(questoes)\n",
    "with tqdm(total=total_porcentagem) as pbar:\n",
    "    for experimento in EXPERIMENTOS:\n",
    "        max_chunks_para_testar = experimento['MAX_CHUNKS_PARA_TESTAR']\n",
    "        for questao in questoes:\n",
    "            id_questao = questao['ID_QUESTAO']\n",
    "            \n",
    "            # 1) SEM NENHUM CONTEXTO\n",
    "            modelo_rag = ''\n",
    "            tipo_pesquisa_chunks = ''\n",
    "            urns_chunks = []\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "    \n",
    "            # 2) COM TODO O CONTEXTO DO DATASET CONSIDERANDO TODOS OS CHUNKS\n",
    "            modelo_rag = 'Gold'\n",
    "            tipo_pesquisa_chunks = 'todos_chunks'\n",
    "            urns_chunks = questao['URN_FUNDAMENTACAO']\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "    \n",
    "            # 3) COM TODO O CONTEXTO DO DATASET CONSIDERANDO TODOS OS CHUNKS APENAS DE ARTIGOS COMPLETOS OU JURISPRUDENCIA\n",
    "            modelo_rag = 'Gold'\n",
    "            tipo_pesquisa_chunks = 'apenas_art'\n",
    "            urns_chunks = questao['URN_FUNDAMENTACAO_APENAS_ART']\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "\n",
    "            # VERIFICA SE É PRA GERAR EXPERIMENTOS COM RAG. SE FOR, ENTRA NO IF E TESTA TAMBÉM COM DIFERENTES RAG\n",
    "            if max_chunks_para_testar > 0:\n",
    "                # 4) CONSIDERANDO DE 1 A 3 CHUNKS PARA CADA MODELO DE RAG E CONSIDERANDO TODOS OS CHUNKS\n",
    "                tipo_pesquisa_chunks = 'todos_chunks'\n",
    "                modelos_rag_disponiveis_para_questao = resultados_pesquisas_todos_chunks[id_questao].keys()\n",
    "                for modelo_rag in modelos_rag_disponiveis_para_questao:\n",
    "                    for n_chunks in range(1, max_chunks_para_testar+1):\n",
    "                        urns_chunks = list(resultados_pesquisas_todos_chunks[id_questao][modelo_rag]['urn'][0:n_chunks])\n",
    "                        executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "                        \n",
    "                # 5) CONSIDERANDO DE 1 A 3 CHUNKS PARA CADA MODELO DE RAG E CONSIDERANDO CHUNKS DE APENAS ARTIGOS\n",
    "                tipo_pesquisa_chunks = 'apenas_art'\n",
    "                modelos_rag_disponiveis_para_questao = resultados_pesquisas_apenas_art[id_questao].keys()\n",
    "                for modelo_rag in modelos_rag_disponiveis_para_questao:\n",
    "                    for n_chunks in range(1, max_chunks_para_testar+1):\n",
    "                        urns_chunks = list(resultados_pesquisas_apenas_art[id_questao][modelo_rag]['urn'][0:n_chunks])\n",
    "                        executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "                    \n",
    "            pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
