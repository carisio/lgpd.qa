{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b063a094-3141-401f-bb6f-7f70b14f7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gzip\n",
    "import re\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "NOME_ARQUIVO_RESULTADOS_PESQUISAS_TODOS_CHUNKS = 'outputs/3 - resultados_pesquisas/resultados_pesquisas_todos_chunks.pickle.gz'\n",
    "NOME_ARQUIVO_RESULTADOS_PESQUISAS_APENAS_ART = 'outputs/3 - resultados_pesquisas/resultados_pesquisas_apenas_art.pickle.gz'\n",
    "\n",
    "# Para abrir os arquivos depois:\n",
    "def load_pickle_gzip(path):\n",
    "    import pickle\n",
    "    import gzip\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "resultados_pesquisas_todos_chunks = load_pickle_gzip(NOME_ARQUIVO_RESULTADOS_PESQUISAS_TODOS_CHUNKS)\n",
    "resultados_pesquisas_apenas_art = load_pickle_gzip(NOME_ARQUIVO_RESULTADOS_PESQUISAS_APENAS_ART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb5836e-b96e-4479-85fe-1b7ece3360f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bm25', 'text-embedding-3-large'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_pesquisas_todos_chunks['1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b2947-62be-4ae6-b597-d54768ae2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_porcentagem = len(EXPERIMENTOS)*len(questoes)\n",
    "with tqdm(total=total_porcentagem) as pbar:\n",
    "    for experimento in EXPERIMENTOS:\n",
    "        for questao in questoes:\n",
    "            id_questao = questao['ID_QUESTAO']\n",
    "            \n",
    "            # 1) SEM NENHUM CONTEXTO\n",
    "            modelo_rag = ''\n",
    "            tipo_pesquisa_chunks = ''\n",
    "            urns_chunks = []\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "    \n",
    "            # 2) COM TODO O CONTEXTO DO DATASET CONSIDERANDO TODOS OS CHUNKS\n",
    "            modelo_rag = 'Gold'\n",
    "            tipo_pesquisa_chunks = 'todos_chunks'\n",
    "            urns_chunks = questao['URN_FUNDAMENTACAO']\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "    \n",
    "            # 3) COM TODO O CONTEXTO DO DATASET CONSIDERANDO TODOS OS CHUNKS APENAS DE ARTIGOS COMPLETOS OU JURISPRUDENCIA\n",
    "            modelo_rag = 'Gold'\n",
    "            tipo_pesquisa_chunks = 'apenas_art'\n",
    "            urns_chunks = questao['URN_FUNDAMENTACAO_APENAS_ART']\n",
    "            executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "\n",
    "            # 4) CONSIDERANDO DE 1 A 3 CHUNKS PARA CADA MODELO DE RAG E CONSIDERANDO TODOS OS CHUNKS\n",
    "            tipo_pesquisa_chunks = 'todos_chunks'\n",
    "            modelos_rag_disponiveis_para_questao = resultados_pesquisas_todos_chunks[id_questao].keys()\n",
    "            for modelo_rag in modelos_rag_disponiveis_para_questao:\n",
    "                for n_chunks in range(1, MAX_CHUNKS_PARA_TESTAR+1):\n",
    "                    urns_chunks = list(resultados_pesquisas_todos_chunks[id_questao][modelo_rag]['urn'][0:n_chunks]))\n",
    "                    executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "                    \n",
    "            # 5) CONSIDERANDO DE 1 A 3 CHUNKS PARA CADA MODELO DE RAG E CONSIDERANDO CHUNKS DE APENAS ARTIGOS\n",
    "            tipo_pesquisa_chunks = 'apenas_art'\n",
    "            modelos_rag_disponiveis_para_questao = resultados_pesquisas_apenas_art[id_questao].keys()\n",
    "            for modelo_rag in modelos_rag_disponiveis_para_questao:\n",
    "                for n_chunks in range(1, MAX_CHUNKS_PARA_TESTAR+1):\n",
    "                    urns_chunks = list(resultados_pesquisas_apenas_art[id_questao][modelo_rag]['urn'][0:n_chunks]))\n",
    "                    executa_experimento_e_atualiza(df_resultados_experimentos, experimento, questao, modelo_rag, tipo_pesquisa_chunks, urns_chunks)\n",
    "            \n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09935b04-2726-4327-b8fb-e91765dae763",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 157 (char 156)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(arquivo, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m linha \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m---> 11\u001b[0m         dado \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(linha)\n\u001b[0;32m     12\u001b[0m         id_questao \u001b[38;5;241m=\u001b[39m dado[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID_QUESTAO\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m         resposta \u001b[38;5;241m=\u001b[39m dado[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRESPOSTA_LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\json\\decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 157 (char 156)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "arquivo = \"outputs/4 - respostas_llms/respostas_llms.jsonl\"  # caminho do seu arquivo\n",
    "\n",
    "respostas_por_questao = defaultdict(set)\n",
    "\n",
    "# Ler o jsonl\n",
    "with open(arquivo, \"r\", encoding=\"utf-8\") as f:\n",
    "    for linha in f:\n",
    "        dado = json.loads(linha)\n",
    "        id_questao = dado[\"ID_QUESTAO\"]\n",
    "        resposta = dado[\"RESPOSTA_LLM\"]\n",
    "        respostas_por_questao[id_questao].add(resposta)\n",
    "\n",
    "# Verificar quais tÃªm respostas diferentes\n",
    "ids_com_respostas_diferentes = [\n",
    "    id_questao\n",
    "    for id_questao, respostas in respostas_por_questao.items()\n",
    "    if len(respostas) > 1\n",
    "]\n",
    "\n",
    "print(\"ID_QUESTAO com respostas diferentes:\")\n",
    "for id_questao in ids_com_respostas_diferentes:\n",
    "    print(id_questao)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
