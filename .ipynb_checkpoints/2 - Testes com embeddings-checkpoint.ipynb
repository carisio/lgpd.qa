{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699d7711-54f2-400d-8ccb-4ddde09b0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import faiss\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from getpass import getpass\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e147c1a-82f3-4ddb-ae33-cb2340bcbd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "KEY OpenAI ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_KEY = getpass(\"KEY OpenAI\")\n",
    "NOME_MODELO_EMB_OPENAI = \"text-embedding-3-large\"\n",
    "DIM_MODELO_EMB_OPENAI = 3072\n",
    "\n",
    "# Modelos disponíveis\n",
    "MODELOS_EMB_NOME_E_DIM_EMB = [(NOME_MODELO_EMB_OPENAI, DIM_MODELO_EMB_OPENAI)]\n",
    "\n",
    "# Modelos para gerar. A ideia é que, uma vez que já foi gerado, pode tirar daqui. Daí ele não precisa carregar o arquivo e ver se está lá\n",
    "MODELOS_EMB_PARA_GERAR = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c512e2f3-2dda-4aeb-876c-908a75a0449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARQUIVO_EMBEDDINGS_CHUNKS = 'outputs/embeddings_chunks.h5'\n",
    "ARQUIVO_EMBEDDINGS_QUESTOES = 'outputs/embeddings_questoes.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6ce12-67ef-46f3-95df-3d027cdac48e",
   "metadata": {},
   "source": [
    "# 1. Carregar as bases de dados de chunks e de questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23eb6ead-8ef3-4174-934d-d728faeed2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "chunks_pesquisa = load_jsonl('inputs/chunks_pesquisa.jsonl')\n",
    "questoes = load_jsonl('inputs/questoes.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189c430-0950-4c03-9981-74a6524c2d7b",
   "metadata": {},
   "source": [
    "Separa as URN/TEXTO dos chunks e as ID/ENUNCIADO das questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd43302-a14a-4b93-895b-b7792bff8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "urn_chunks = [c['URN'] for c in chunks_pesquisa]\n",
    "texto_chunks = [c['TEXTO'] for c in chunks_pesquisa]\n",
    "\n",
    "id_questoes = [q['ID_QUESTAO'] for q in questoes]\n",
    "enunciado_questoes = [q['ENUNCIADO_COM_ALTERNATIVAS'] for q in questoes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a85c04-7312-4a55-adf7-ebd5caf57596",
   "metadata": {},
   "source": [
    "## 1.1 Gera qrels no formato considerando todos os chunks e no nível de artigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944867d8-47ed-4f1f-9db9-696eb9e43d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um qrels no formato esperado\n",
    "id_questao = []\n",
    "urn_chunk = []\n",
    "score = []\n",
    "rank = []\n",
    "for q in questoes:\n",
    "    total_docs = len(q['URN_FUNDAMENTACAO'])\n",
    "    id_questao += [q['ID_QUESTAO']] * total_docs\n",
    "    urn_chunk += q['URN_FUNDAMENTACAO']\n",
    "    score += [1] * total_docs\n",
    "    rank += list(range(1, total_docs+1))\n",
    "\n",
    "qrels_todos_chunks = pd.DataFrame({\n",
    "    \"QUERY_KEY\": id_questao,\n",
    "    \"DOC_KEY\": urn_chunk,\n",
    "    \"SCORE\": score,\n",
    "    \"RANK\": rank\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7799824d-8a75-4af6-8ba5-6d431a746542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "\n",
    "padrao = re.compile(r'!art\\d{1,3}')\n",
    "\n",
    "questoes_fund_apenas_art = copy.deepcopy(questoes)\n",
    "\n",
    "for questao in questoes_fund_apenas_art:\n",
    "    nova_fundamentacao = []\n",
    "\n",
    "    for texto in questao.get(\"URN_FUNDAMENTACAO\", []):\n",
    "        match = padrao.search(texto)\n",
    "\n",
    "        if match:\n",
    "            # corta exatamente no final de !artX\n",
    "            nova_fundamentacao.append(texto[:match.end()])\n",
    "        else:\n",
    "            nova_fundamentacao.append(texto)\n",
    "\n",
    "    questao[\"URN_FUNDAMENTACAO\"] = list(set(nova_fundamentacao))\n",
    "\n",
    "# Cria um qrels no formato esperado\n",
    "id_questao = []\n",
    "urn_chunk = []\n",
    "score = []\n",
    "rank = []\n",
    "for q in questoes_fund_apenas_art:\n",
    "    total_docs = len(q['URN_FUNDAMENTACAO'])\n",
    "    id_questao += [q['ID_QUESTAO']] * total_docs\n",
    "    urn_chunk += q['URN_FUNDAMENTACAO']\n",
    "    score += [1] * total_docs\n",
    "    rank += list(range(1, total_docs+1))\n",
    "\n",
    "qrels_apenas_art = pd.DataFrame({\n",
    "    \"QUERY_KEY\": id_questao,\n",
    "    \"DOC_KEY\": urn_chunk,\n",
    "    \"SCORE\": score,\n",
    "    \"RANK\": rank\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad8263-c777-4181-95ab-c8d38fe0ed8c",
   "metadata": {},
   "source": [
    "# 2. Criar as estruturas em arquivos H5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fedf22-4d63-475e-98e4-d21a0b467246",
   "metadata": {},
   "source": [
    "Garante que o arquivo existe e que tem os datasets nele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b07a6e-25fd-421e-9022-a2ad14fc7c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_estrutura_embeddings(arquivo, nome_id, lista_id):\n",
    "    with h5py.File(arquivo, \"a\") as f:\n",
    "        chunk_size=128\n",
    "        n = len(lista_id)\n",
    "        \n",
    "        if nome_id not in f:\n",
    "            # Quando criar o dataset para as URNS/ID, já cria ele preenchido com todas elas\n",
    "            f.create_dataset(\n",
    "                nome_id,\n",
    "                data=np.array(lista_id, dtype=\"S\"),  # grava tudo de uma vez\n",
    "                maxshape=(None,),\n",
    "                dtype=h5py.string_dtype(encoding=\"utf-8\"),\n",
    "                chunks=True\n",
    "            )\n",
    "    \n",
    "        for nome_modelo, dim_modelo in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "            if nome_modelo not in f:\n",
    "                # Quando criar o dataset com os embeddings do modelo, cria preenchido com nan\n",
    "                ds = f.create_dataset(\n",
    "                    nome_modelo,\n",
    "                    shape=(n, dim_modelo),\n",
    "                    maxshape=(n, dim_modelo),\n",
    "                    dtype=np.float16,\n",
    "                    compression=\"gzip\",\n",
    "                    chunks=(chunk_size, dim_modelo)\n",
    "                )\n",
    "                ds[:] = np.nan\n",
    "\n",
    "criar_estrutura_embeddings(ARQUIVO_EMBEDDINGS_CHUNKS, 'urn', urn_chunks)\n",
    "criar_estrutura_embeddings(ARQUIVO_EMBEDDINGS_QUESTOES, 'id', id_questoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76b869-ce9b-4c3d-9293-650a72f861c1",
   "metadata": {},
   "source": [
    "Funções auxiliares para saber se já existe embedding associado e para atualizar embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a3a3a5a-2967-44bb-b5de-146d0c2888ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def existe_embedding(arquivo, nome_modelo, idx):\n",
    "    with h5py.File(arquivo, \"a\") as f:\n",
    "        ds = f[nome_modelo]\n",
    "\n",
    "        return not np.isnan(ds[idx, 0])\n",
    "    \n",
    "def atualizar_embedding(arquivo, nome_modelo, idx, embedding):\n",
    "    with h5py.File(arquivo, \"a\") as f:\n",
    "        ds = f[nome_modelo]\n",
    "\n",
    "        ds[idx] = np.asarray(embedding, dtype=np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6abca-056a-4c75-93dc-aeae4abb8f93",
   "metadata": {},
   "source": [
    "# 2. Cria embeddings para o campo TEXTO (chunks) e para o campo ENUNCIADO_COM_ALTERNATIVAS (questões)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c236b9b-62e3-4ab4-86e4-b731b2574099",
   "metadata": {},
   "source": [
    "Funções auxiliares para geração de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a83e7e2-4295-4b00-a69f-a5f31e84cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_emb_com_retry(id, texto, nome_modelo, func_get_emb):\n",
    "    try:\n",
    "        return func_get_emb(nome_modelo, texto)\n",
    "    except Exception as e:\n",
    "        print(f'id: {id}. Chunk muito grande. Reduzindo em 20%')\n",
    "        print(e.message)\n",
    "        # Extrai, da mensagem de erro, o total de tokens requisitados e diminui o texto proporcionalmente.\n",
    "        # No caso da openai, eles aceitam 8192 de entrada.\n",
    "        # Na hora de diminuir, garante que vai diminuir pelo menos 20% do texto de entrada\n",
    "        reduzir_para = int(len(texto)*.8)\n",
    "        if nome_modelo == EMB_MODEL_OPENAI:\n",
    "            match = re.search(r'requested\\s+(\\d+)\\s+tokens', ex.message)\n",
    "             # Se não achou a mensagem, considera 8192 para reduzir em 20%\n",
    "            total_token_requisitados = int(match.group(1)) if match else 8192\n",
    "            reduzir_para = int(min(8192/total_token_requisitados, 0.8) * len(texto))\n",
    "            \n",
    "        return extrai_emb_com_retry(id, texto[:reduzir_para], nome_modelo, func_get_emb)\n",
    "\n",
    "def extrai_emb_chunks_e_salva(nome_modelo, func_get_emb):\n",
    "    for chunk in tqdm(chunks_pesquisa):\n",
    "        urn = chunk['URN']\n",
    "        texto = chunk['TEXTO']\n",
    "    \n",
    "        if nome_modelo not in emb_chunks[urn]:\n",
    "            emb_chunks[urn][nome_modelo] = extrai_emb_com_retry(urn, texto, nome_modelo, func_get_emb)\n",
    "            #emb_chunks[urn][nome_modelo] = func_get_emb(nome_modelo, texto)\n",
    "            salvar_embeddings(NOME_ARQUIVO_EMBEDDINGS_CHUNKS, emb_chunks)\n",
    "\n",
    "def extrai_emb_questoes_e_salva(nome_modelo, func_get_emb):\n",
    "    for q in tqdm(questoes):\n",
    "        id = q['ID_QUESTAO']\n",
    "        texto = q['ENUNCIADO_COM_ALTERNATIVAS']\n",
    "    \n",
    "        if nome_modelo not in emb_questoes[id]:\n",
    "            emb_questoes[id][nome_modelo] = extrai_emb_com_retry(id, texto, nome_modelo, func_get_emb)\n",
    "            salvar_embeddings(NOME_ARQUIVO_EMBEDDINGS_QUESTOES, emb_questoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946dc23-2e2e-4af9-8456-bb10aa6c56d7",
   "metadata": {},
   "source": [
    "Função para extrair embeddings usando o modelo da openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ff91428-56da-4a45-bfe0-d64c60f3303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_openai = OpenAI(api_key=OPENAI_KEY, base_url=None)\n",
    "def extrair_embeddings_openai(nome_modelo, texto):\n",
    "   return client_openai.embeddings.create(input = [texto], model=nome_modelo).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4fb6c1-e035-4e48-b184-a41383d0f675",
   "metadata": {},
   "source": [
    "Agora gera os embeddings dos chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50682a2c-2da0-49c5-8769-815b62464996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 7036/7036 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Varre todos os urns\n",
    "for idx, urn in enumerate(tqdm(urn_chunks)):\n",
    "    texto = texto_chunks[idx]\n",
    "\n",
    "    for nome_modelo, _ in MODELOS_EMB_PARA_GERAR:\n",
    "        if not existe_embedding(ARQUIVO_EMBEDDINGS_CHUNKS, nome_modelo, idx):\n",
    "            # TODO: Depois generalizar isso daqui para não ficar tendo que fazer if com o nome dos modelos\n",
    "            if nome_modelo == NOME_MODELO_EMB_OPENAI:\n",
    "                emb_gerado = extrair_embeddings_openai(nome_modelo, texto)\n",
    "                atualizar_embedding(ARQUIVO_EMBEDDINGS_CHUNKS, nome_modelo, idx, emb_gerado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aece113-b7ef-4247-9b39-e7ca32ba1ce3",
   "metadata": {},
   "source": [
    "Gera os embeddings dos enunciados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c30b27-54e4-4e83-b89b-4aee7f85ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Varre todos os enunciado\n",
    "for idx, id in enumerate(tqdm(id_questoes)):\n",
    "    texto = enunciado_questoes[idx]\n",
    "\n",
    "    for nome_modelo, _ in MODELOS_EMB_PARA_GERAR:\n",
    "        if not existe_embedding(ARQUIVO_EMBEDDINGS_QUESTOES, nome_modelo, idx):\n",
    "            # TODO: Depois generalizar isso daqui para não ficar tendo que fazer if com o nome dos modelos\n",
    "            if nome_modelo == NOME_MODELO_EMB_OPENAI:\n",
    "                emb_gerado = extrair_embeddings_openai(nome_modelo, texto)\n",
    "                atualizar_embedding(ARQUIVO_EMBEDDINGS_QUESTOES, nome_modelo, idx, emb_gerado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fbff6-6326-4c01-8890-17f8e3568756",
   "metadata": {},
   "source": [
    "# 3. Pesquisa semântica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db987e4-5cbb-4eba-9b3f-fb113deca87f",
   "metadata": {},
   "source": [
    "## 3.1. Testes com similaridade de cosseno e pandas\n",
    "\n",
    "Pode desconsiderar esse código. É só pra comparar com o FAISS depois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a29c92e7-8cca-4779-9e61-a80e2ce75b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dict_embeddings(arquivo, coluna_id):\n",
    "    embeddings = {}\n",
    "\n",
    "    with h5py.File(arquivo, \"r\") as f:\n",
    "        embeddings[coluna_id] = f[coluna_id][:].astype(str)\n",
    "        for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "            embeddings[nome_modelo] = f[nome_modelo][:]\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af296de-3dc8-4185-951d-a73d4dd8618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emb_chunks = gerar_dict_embeddings(ARQUIVO_EMBEDDINGS_CHUNKS, 'urn')\n",
    "dict_emb_questoes = gerar_dict_embeddings(ARQUIVO_EMBEDDINGS_QUESTOES, 'id')\n",
    "\n",
    "df_emb_chunks = pd.DataFrame({\n",
    "    \"urn\": dict_emb_chunks[\"urn\"]\n",
    "})\n",
    "df_emb_questoes = pd.DataFrame({\n",
    "    \"id\": dict_emb_questoes[\"id\"]\n",
    "})\n",
    "\n",
    "for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "    df_emb_chunks[nome_modelo] = list(dict_emb_chunks[nome_modelo])\n",
    "    df_emb_questoes[nome_modelo] = list(dict_emb_questoes[nome_modelo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf22aad2-9484-4664-a728-03982271cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_proximos(id_questao, nome_modelo, n_chunks = 20):\n",
    "    emb_questao = df_emb_questoes[nome_modelo][df_emb_questoes.id == id_questao].values[0]\n",
    "\n",
    "    df_chunks_similares = df_emb_chunks.copy()\n",
    "    df_chunks_similares['similarity'] = df_chunks_similares[nome_modelo].apply(lambda x: cosine_similarity([x], [emb_questao])[0,0])\n",
    "    df_chunks_similares = df_chunks_similares.sort_values(\"similarity\", ascending=False)\n",
    "    \n",
    "    return df_chunks_similares.head(n_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e28174f-8e10-42c2-966d-45b35420e52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urn:lex:br:federal:lei:2018-08-14;13709!art5_cpt_inc6',\n",
       " 'urn:lex:br:autoridade.nacional.protecao.dados;conselho.diretor:resolucao:2024-07-16;18;anexo.1!art2_cpt_inc3',\n",
       " 'urn:lex:br:federal:lei:2018-08-14;13709!art23_cpt_inc3']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para testar:\n",
    "get_chunks_proximos('1',NOME_MODELO_EMB_OPENAI, 3).urn.iloc[0:3].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3cff97-d33d-43a9-b734-48764a151cba",
   "metadata": {},
   "source": [
    "## 3.2. Testes com FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4232d514-552d-45fd-a600-dac68b580a20",
   "metadata": {},
   "source": [
    "Carregar e normalizar embeddings.\n",
    "\n",
    "Obs.: Os embeddings da OpenAI já são normalizados (mas há uma perda na conversão de f32 pra f16 para salvar no H5), nem precisaria disso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e831a3d-ca00-4cf5-946f-567b2a1388ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_embeddings_faiss(arquivo, coluna_id, nome_modelo):\n",
    "    with h5py.File(arquivo, \"r\") as f:\n",
    "        ids = f[coluna_id][:].astype(str)\n",
    "        emb = f[nome_modelo][:].astype(np.float32)\n",
    "\n",
    "    return ids, emb\n",
    "\n",
    "# A ideia dessa função é, uma vez carregado todos os embeddings, filtrar apenas aqueles\n",
    "# que batem com a máscara. Será usado para indexar apenas os embeddings que se referem a artigos completos\n",
    "urns_chunks_pesquisa_apenas_art = { c['URN'] for c in chunks_pesquisa if c['TIPO'] == 'ART' or c['TIPO'] == 'JUR'}\n",
    "def filtro_apenas_art(urn):\n",
    "    return urn in urns_chunks_pesquisa_apenas_art\n",
    "\n",
    "def filtro_seleciona_tudo(_):\n",
    "    return True\n",
    "    \n",
    "def filtrar_embeddings(urns, emb, func_filtro):\n",
    "    mask = np.array([func_filtro(i) for i in urns], dtype=bool)\n",
    "\n",
    "    return urns[mask], emb[mask]\n",
    "\n",
    "def normalizar_embeddings(x):\n",
    "    faiss.normalize_L2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f681138-1c84-43e8-83b4-b7f2e0336bfc",
   "metadata": {},
   "source": [
    "Criar o índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54b14efc-8630-448d-8a83-09838264771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice criado com 7036 vetores\n",
      "Índice criado com 1095 vetores\n"
     ]
    }
   ],
   "source": [
    "def criar_mapa_indice_chunks(arquivo, filtro_seleciona_id):\n",
    "    mapa_indice_faiss = {}\n",
    "    \n",
    "    for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "        urns, emb_chunks = carregar_embeddings_faiss(arquivo, 'urn', nome_modelo)\n",
    "        urns, emb_chunks = filtrar_embeddings(urns, emb_chunks, filtro_seleciona_id)\n",
    "                                           \n",
    "        emb_chunks = normalizar_embeddings(emb_chunks)\n",
    "        dim = emb_chunks.shape[1]\n",
    "        \n",
    "        index_faiss = faiss.IndexFlatL2(dim)\n",
    "        index_faiss.add(emb_chunks)\n",
    "    \n",
    "        mapa_indice_faiss[nome_modelo] = index_faiss\n",
    "        print(f\"Índice criado com {index_faiss.ntotal} vetores\")\n",
    "    \n",
    "    return urns, mapa_indice_faiss\n",
    "\n",
    "urns_todos_chunks, mapa_indice_faiss_todos_chunks_por_modelo = criar_mapa_indice_chunks(ARQUIVO_EMBEDDINGS_CHUNKS, filtro_seleciona_tudo)\n",
    "urns_apenas_art, mapa_indice_faiss_apenas_art_por_modelo = criar_mapa_indice_chunks(ARQUIVO_EMBEDDINGS_CHUNKS, filtro_apenas_art)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984032d-3c3c-4f70-8c69-93dc07147fec",
   "metadata": {},
   "source": [
    "Função de busca no índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "635ccf91-6415-422c-8259-264c7545443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa embeddings da questão por modelo\n",
    "mapa_emb_questao_por_modelo = {}\n",
    "for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "    ids_q, emb_q = carregar_embeddings_faiss(ARQUIVO_EMBEDDINGS_QUESTOES, 'id', nome_modelo)\n",
    "    emb_q = normalizar_embeddings(emb_q)\n",
    "    mapa_emb_questao_por_modelo[nome_modelo] = emb_q\n",
    "\n",
    "# Mapa id da questão por índice. Considera que todos os embeddings foram criados sequencialmente (foi feito assim mesmo)\n",
    "mapa_id_questao = {id_: i for i, id_ in enumerate(ids_q)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "311bc033-b4eb-4309-90b1-dd7703a58b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_proximos_faiss(id_questao, nome_modelo, urns, mapa_indices, n_chunks=20):\n",
    "    idx_q = mapa_id_questao[id_questao]\n",
    "    query =  mapa_emb_questao_por_modelo[nome_modelo][idx_q:idx_q+1]  # shape (1, dim)\n",
    "    \n",
    "    distancias, indices = mapa_indices[nome_modelo].search(query, n_chunks)\n",
    "\n",
    "    resultados = []\n",
    "    for rank, (i, d) in enumerate(zip(indices[0], distancias[0])):\n",
    "        resultados.append({\n",
    "            \"rank\": rank + 1,\n",
    "            \"urn\": urns[i],\n",
    "            \"distancia_l2\": float(d),\n",
    "            \"similaridade_cosine_aprox\": 1 - d / 2\n",
    "        })\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181283e0-9136-48d2-9a58-c49ff87d9b0d",
   "metadata": {},
   "source": [
    "Alguns testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b46f250-4add-4421-8170-e1f4a01c73e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rank': 1,\n",
       "  'urn': 'tema_stf_483',\n",
       "  'distancia_l2': 0.8037692904472351,\n",
       "  'similaridade_cosine_aprox': 0.5981153547763824},\n",
       " {'rank': 2,\n",
       "  'urn': 'urn:lex:br:federal:lei:2018-08-14;13709!art23_cpt',\n",
       "  'distancia_l2': 0.9373655319213867,\n",
       "  'similaridade_cosine_aprox': 0.5313172340393066},\n",
       " {'rank': 3,\n",
       "  'urn': 'urn:lex:br:federal:lei:2018-08-14;13709!art23_cpt_inc4',\n",
       "  'distancia_l2': 0.9542654752731323,\n",
       "  'similaridade_cosine_aprox': 0.5228672623634338}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chunks_proximos_faiss('675', NOME_MODELO_EMB_OPENAI, urns_todos_chunks, mapa_indice_faiss_todos_chunks_por_modelo, n_chunks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6af2077f-825f-4222-9908-ec9585de1c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rank': 1,\n",
       "  'urn': 'tema_stf_483',\n",
       "  'distancia_l2': 0.8037692904472351,\n",
       "  'similaridade_cosine_aprox': 0.5981153547763824},\n",
       " {'rank': 2,\n",
       "  'urn': 'urn:lex:br:federal:lei:2011-11-18;12527!art34',\n",
       "  'distancia_l2': 0.9836373925209045,\n",
       "  'similaridade_cosine_aprox': 0.5081813037395477},\n",
       " {'rank': 3,\n",
       "  'urn': 'urn:lex:br:federal:lei:2018-08-14;13709!art23',\n",
       "  'distancia_l2': 0.9871585369110107,\n",
       "  'similaridade_cosine_aprox': 0.5064207315444946}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chunks_proximos_faiss('675', NOME_MODELO_EMB_OPENAI, urns_apenas_art, mapa_indice_faiss_apenas_art_por_modelo, n_chunks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bac8f1-3a7e-423a-8a42-9c4ab73e1b3a",
   "metadata": {},
   "source": [
    "Calcula as métricas para toda a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7832792-a480-4710-bf8f-7013eaac6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pesquisa_semantica(urns_nos_indices, mapa_indice_faiss, n_chunks=20):   \n",
    "    mapa_df_resultado_por_modelo = {}\n",
    "\n",
    "    total_porcentagem = len(MODELOS_EMB_NOME_E_DIM_EMB)*len(questoes)\n",
    "    with tqdm(total=total_porcentagem) as pbar:\n",
    "        for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "            col_resultado_id_questao=[]\n",
    "            col_resultado_urn_chunk=[]\n",
    "            col_resultado_rank=[]\n",
    "            \n",
    "            for q in questoes:\n",
    "                id_questao = q['ID_QUESTAO']\n",
    "                resultados_para_id_questao = get_chunks_proximos_faiss(id_questao, nome_modelo, urns_nos_indices, mapa_indice_faiss, n_chunks)\n",
    "                \n",
    "                ids_questao = [id_questao] * len(resultados_para_id_questao)\n",
    "                primeiros_20_urns = [item['urn'] for item in resultados_para_id_questao]\n",
    "                ranking = [item['rank'] for item in resultados_para_id_questao]\n",
    "        \n",
    "                col_resultado_id_questao.extend(ids_questao)\n",
    "                col_resultado_urn_chunk.extend(primeiros_20_urns)\n",
    "                col_resultado_rank.extend(ranking)\n",
    "    \n",
    "                pbar.update(1)\n",
    "        \n",
    "            df_resultados_por_modelo = pd.DataFrame({\n",
    "                \"QUERY_KEY\": col_resultado_id_questao,\n",
    "                \"DOC_KEY\": col_resultado_urn_chunk,\n",
    "                \"RANK\": col_resultado_rank,\n",
    "            })\n",
    "            mapa_df_resultado_por_modelo[nome_modelo] = df_resultados_por_modelo\n",
    "    \n",
    "    return mapa_df_resultado_por_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "193b8e60-cd69-4c00-b4c7-636811a0d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 700/700 [00:04<00:00, 171.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2217.05it/s]\n"
     ]
    }
   ],
   "source": [
    "mapa_resultados_todos_chunks_por_modelo = pesquisa_semantica(urns_todos_chunks, mapa_indice_faiss_todos_chunks_por_modelo, n_chunks=20)\n",
    "mapa_resultados_apenas_art_por_modelo = pesquisa_semantica(urns_apenas_art, mapa_indice_faiss_apenas_art_por_modelo, n_chunks=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f47a887-59e4-43fb-8cb0-db01e62ef66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "from metricas import histograma_metricas, boxplot_metricas, metricas\n",
    "\n",
    "mapa_metricas_todos_chunks = {}\n",
    "mapa_metricas_apenas_art = {}\n",
    "\n",
    "for nome_modelo, _ in tqdm(MODELOS_EMB_NOME_E_DIM_EMB):\n",
    "    mapa_metricas_todos_chunks[nome_modelo] = metricas(mapa_resultados_todos_chunks_por_modelo[nome_modelo], qrels_todos_chunks, aproximacao_trec_eval=True, k=[5, 10, 20])\n",
    "    mapa_metricas_apenas_art[nome_modelo] = metricas(mapa_resultados_apenas_art_por_modelo[nome_modelo], qrels_apenas_art, aproximacao_trec_eval=True, k=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cd8f3b3-e2a3-48a3-8673-3dcefd0783ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################## text-embedding-3-large ##########################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@20</th>\n",
       "      <th>R@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>MRR@20</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.174286</td>\n",
       "      <td>0.129143</td>\n",
       "      <td>0.082929</td>\n",
       "      <td>0.468491</td>\n",
       "      <td>0.599537</td>\n",
       "      <td>0.710422</td>\n",
       "      <td>0.437310</td>\n",
       "      <td>0.452902</td>\n",
       "      <td>0.458488</td>\n",
       "      <td>0.391336</td>\n",
       "      <td>0.450069</td>\n",
       "      <td>0.490156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.150996</td>\n",
       "      <td>0.112110</td>\n",
       "      <td>0.069109</td>\n",
       "      <td>0.422703</td>\n",
       "      <td>0.408479</td>\n",
       "      <td>0.377406</td>\n",
       "      <td>0.400626</td>\n",
       "      <td>0.385735</td>\n",
       "      <td>0.379604</td>\n",
       "      <td>0.361440</td>\n",
       "      <td>0.344462</td>\n",
       "      <td>0.326977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149782</td>\n",
       "      <td>0.231378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363318</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>0.489132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>0.695302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              P@5        P@10        P@20         R@5        R@10        R@20  \\\n",
       "count  700.000000  700.000000  700.000000  700.000000  700.000000  700.000000   \n",
       "mean     0.174286    0.129143    0.082929    0.468491    0.599537    0.710422   \n",
       "std      0.150996    0.112110    0.069109    0.422703    0.408479    0.377406   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.100000    0.050000    0.000000    0.200000    0.400000   \n",
       "50%      0.200000    0.100000    0.050000    0.333333    0.666667    1.000000   \n",
       "75%      0.200000    0.200000    0.100000    1.000000    1.000000    1.000000   \n",
       "max      0.800000    0.600000    0.400000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            MRR@5      MRR@10      MRR@20      nDCG@5     nDCG@10     nDCG@20  \n",
       "count  700.000000  700.000000  700.000000  700.000000  700.000000  700.000000  \n",
       "mean     0.437310    0.452902    0.458488    0.391336    0.450069    0.490156  \n",
       "std      0.400626    0.385735    0.379604    0.361440    0.344462    0.326977  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.125000    0.125000    0.000000    0.149782    0.231378  \n",
       "50%      0.333333    0.333333    0.333333    0.363318    0.430677    0.489132  \n",
       "75%      1.000000    1.000000    1.000000    0.630930    0.630930    0.695302  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "    print(f'########################## {nome_modelo} ##########################')\n",
    "    display(mapa_metricas_todos_chunks[nome_modelo].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3892c29c-3651-4bd2-9cba-ca87fd6d9e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################## text-embedding-3-large ##########################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@20</th>\n",
       "      <th>R@5</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>MRR@20</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>700.00000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.22000</td>\n",
       "      <td>0.123429</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>0.760466</td>\n",
       "      <td>0.820813</td>\n",
       "      <td>0.882116</td>\n",
       "      <td>0.724214</td>\n",
       "      <td>0.729605</td>\n",
       "      <td>0.732060</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.717888</td>\n",
       "      <td>0.736840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.15186</td>\n",
       "      <td>0.087696</td>\n",
       "      <td>0.049656</td>\n",
       "      <td>0.378397</td>\n",
       "      <td>0.342252</td>\n",
       "      <td>0.287777</td>\n",
       "      <td>0.392427</td>\n",
       "      <td>0.383271</td>\n",
       "      <td>0.378775</td>\n",
       "      <td>0.365633</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.326285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877215</td>\n",
       "      <td>0.919721</td>\n",
       "      <td>0.920236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             P@5        P@10        P@20         R@5        R@10        R@20  \\\n",
       "count  700.00000  700.000000  700.000000  700.000000  700.000000  700.000000   \n",
       "mean     0.22000    0.123429    0.068571    0.760466    0.820813    0.882116   \n",
       "std      0.15186    0.087696    0.049656    0.378397    0.342252    0.287777   \n",
       "min      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.20000    0.100000    0.050000    0.500000    0.800000    1.000000   \n",
       "50%      0.20000    0.100000    0.050000    1.000000    1.000000    1.000000   \n",
       "75%      0.20000    0.100000    0.050000    1.000000    1.000000    1.000000   \n",
       "max      0.80000    0.500000    0.250000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            MRR@5      MRR@10      MRR@20      nDCG@5     nDCG@10     nDCG@20  \n",
       "count  700.000000  700.000000  700.000000  700.000000  700.000000  700.000000  \n",
       "mean     0.724214    0.729605    0.732060    0.694030    0.717888    0.736840  \n",
       "std      0.392427    0.383271    0.378775    0.365633    0.346010    0.326285  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.500000    0.500000    0.500000    0.500000    0.500000    0.500000  \n",
       "50%      1.000000    1.000000    1.000000    0.877215    0.919721    0.920236  \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for nome_modelo, _ in MODELOS_EMB_NOME_E_DIM_EMB:\n",
    "    print(f'########################## {nome_modelo} ##########################')\n",
    "    display(mapa_metricas_apenas_art[nome_modelo].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
